{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c64306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-macosx_10_11_x86_64.whl (207.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 207.1 MB 41 kB/s  eta 0:00:01   |█                               | 6.8 MB 1.4 MB/s eta 0:02:23     |███▎                            | 21.4 MB 3.7 MB/s eta 0:00:50     |█████▉                          | 37.7 MB 6.7 MB/s eta 0:00:26     |██████                          | 38.5 MB 6.7 MB/s eta 0:00:26     |█████████▎                      | 59.8 MB 3.8 MB/s eta 0:00:39     |█████████▍                      | 60.6 MB 3.8 MB/s eta 0:00:39     |█████████▊                      | 63.2 MB 3.8 MB/s eta 0:00:38     |██████████████                  | 91.0 MB 5.7 MB/s eta 0:00:21     |██████████████████              | 116.2 MB 3.3 MB/s eta 0:00:28     |█████████████████████▏          | 137.1 MB 6.4 MB/s eta 0:00:11     |███████████████████████         | 149.3 MB 8.2 MB/s eta 0:00:08\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp38-cp38-macosx_10_10_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 5.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting gast<0.5.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.20.1)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.3-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "\u001b[K     |████████████████████████████████| 463 kB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.32.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-2-py2.py3-none-macosx_10_9_x86_64.whl (12.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2 MB 5.9 MB/s eta 0:00:01     |██████                          | 2.3 MB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 19.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 18.5 MB/s eta 0:00:01     |█████▋                          | 1.0 MB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 13.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 141 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 4.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.10.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 4.7 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, cachetools, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-4.2.4 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.43.0 importlib-metadata-4.10.1 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 opt-einsum-3.3.0 protobuf-3.19.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.23.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "139b5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19fa07c",
   "metadata": {},
   "source": [
    "# Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e8403",
   "metadata": {},
   "source": [
    "Обучите word2vec модели с негативным семплированием (cbow и skip-gram) с помощью tensorflow аналогично тому, как это было сделано в семинаре. Вам нужно изменить следующие пункты: 1) добавьте лемматизацию в предобработку (любым способом)\n",
    "2) измените размер окна на 6 для cbow и 12 для skip gram (обратите внимание, что размер окна = #слов слева + #слов справа, в gen_batches в семинаре window не так используется)\n",
    "3) измените часть с np.random.randint(vocab_size) так, чтобы случайные негативные примеры выбирались обратно пропорционально частотностям слов (частотные должны выбираться реже, а редкие чаще)\n",
    "\n",
    "Выберете несколько не похожих по смыслу слов, и протестируйте полученные эмбединги (найдите ближайшие слова и оцените правильность, как в семинаре)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "23de27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = open('wiki_data.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502dd6ad",
   "metadata": {},
   "source": [
    "### Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f88d69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf5e25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(token):\n",
    "    return morph.parse(token)[0].normal_form\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    tokens = [lemmatize(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "532d5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in wiki:\n",
    "    vocab.update(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2806a918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356181"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "58d46603",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 30:\n",
    "        filtered_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "192a4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = { 'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c269b73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11988"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "937afb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "04245d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11988"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "28353d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for text in wiki:\n",
    "    tokens = preprocess(text)\n",
    "    ids = [word2id[token] for token in tokens if token in word2id]\n",
    "    sentences.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "09925e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = dict()\n",
    "summ = 0\n",
    "for word in word2id.keys():\n",
    "    summ += vocab[word]\n",
    "for word in word2id.keys():\n",
    "    probs[word] = (vocab[word] / summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ed5836b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11988"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "28e98d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_id = dict()\n",
    "for word in id2word.keys():\n",
    "    probs_id[word] = probs[id2word[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e13720fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11988"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8569aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_probability = [(1-x) for x in probs_id.values()]\n",
    "inverse_probability = [x/sum(inverse_probability) for x in inverse_probability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "189d9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "789e417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_choice(values, weights):\n",
    "    total = 0\n",
    "    cum_weights = []\n",
    "    for w in weights:\n",
    "        total += w\n",
    "        cum_weights.append(total)\n",
    "    x = random() * total\n",
    "    i = bisect(cum_weights, x)\n",
    "    return values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b5615207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3772"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_choice(list(probs_id.keys()), inverse_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a6c861",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "46e7f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "window = 3\n",
    "for sent in sentences[:10000]:\n",
    "    for i in range(len(sent)-1):\n",
    "        word = sent[i]\n",
    "        context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "        \n",
    "        X.append(context)\n",
    "        y.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6eab3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=10, padding='post')\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "273ac893",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0f5af895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batches_cbow(sentences, probs_id, inverse_probability, window = 3, batch_size=1000):\n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "\n",
    "                X_target.append(word)\n",
    "                X_context.append(context)\n",
    "                y.append(1)\n",
    "\n",
    "                X_target.append(np.random.choice(list(probs_id.keys()), p=list(inverse_probability)))\n",
    "                X_context.append(context)\n",
    "                y.append(0)\n",
    "\n",
    "                if len(X_target) == batch_size:\n",
    "                    X_target = np.array(X_target)\n",
    "                    X_context = tf.keras.preprocessing.sequence.pad_sequences(X_context, maxlen=window*2)\n",
    "                    y = np.array(y)\n",
    "                    yield ((X_target, X_context), y)\n",
    "                    X_target = []\n",
    "                    X_context = []\n",
    "                    y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "56519fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = tf.keras.layers.Input(shape=(1,))\n",
    "inputs_context = tf.keras.layers.Input(shape=(10,))\n",
    "\n",
    "\n",
    "embeddings_target = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = tf.keras.layers.Flatten()(embeddings_target)\n",
    "context = tf.keras.layers.Lambda(lambda x: tf.keras.backend.sum(x, axis=1))(embeddings_context)\n",
    "dot = tf.keras.layers.Dot(1)([target, context])\n",
    "\n",
    "outputs = tf.keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f2956b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 6390s 1s/step - loss: 0.3586 - accuracy: 0.8454 - val_loss: 0.3033 - val_accuracy: 0.8773\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 6716s 1s/step - loss: 0.2373 - accuracy: 0.9021 - val_loss: 0.3220 - val_accuracy: 0.8738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3313bac40>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen_batches_cbow(sentences[:10000], probs_id=probs_id, inverse_probability=inverse_probability, window=3),\n",
    "          validation_data=gen_batches_cbow(sentences[10000:],  probs_id=probs_id, inverse_probability=inverse_probability, window=3),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=5000,\n",
    "          validation_steps=30,\n",
    "         epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d557c7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0464662 ,  0.04117003,  0.00748137, ...,  0.01296938,\n",
       "         0.02333159, -0.00398258],\n",
       "       [-0.04407486, -0.03842119,  0.00643934, ..., -0.00542885,\n",
       "        -0.03787053, -0.0495595 ],\n",
       "       [-0.03655779, -0.04601256, -0.01318984, ..., -0.03524858,\n",
       "        -0.04634327, -0.03450954],\n",
       "       ...,\n",
       "       [-0.02512736,  0.03204944, -0.01609343, ..., -0.01847487,\n",
       "        -0.00522197,  0.0364614 ],\n",
       "       [ 0.0124413 , -0.02985858, -0.01330297, ..., -0.00751491,\n",
       "        -0.04469   , -0.02433776],\n",
       "       [ 0.00746178,  0.00550408,  0.04247456, ..., -0.04270409,\n",
       "         0.03684458, -0.01659775]], dtype=float32)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1b1846ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, embeddings):\n",
    "    similar = [id2word[i] for i in \n",
    "               cosine_distances(embeddings[word2id[word]].reshape(1, -1), embeddings).argsort()[0][:10]]\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0924d0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['окно',\n",
       " 'сбор',\n",
       " 'оппонент',\n",
       " 'ганс',\n",
       " 'стивенс',\n",
       " 'опера',\n",
       " 'департамент',\n",
       " 'преимущественно',\n",
       " 'декабрь',\n",
       " '£']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('окно', embeddings_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4ea6578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['кот',\n",
       " 'предлагать',\n",
       " 'бакунин',\n",
       " '9-й',\n",
       " 'узбекистан',\n",
       " 'мотив',\n",
       " 'вывоз',\n",
       " 'прибыть',\n",
       " 'исполнить',\n",
       " 'group']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('кот', embeddings_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5905a53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['город',\n",
       " 'капелла',\n",
       " 'охранять',\n",
       " '1864',\n",
       " 'фигурист',\n",
       " 'блокировать',\n",
       " 'надо',\n",
       " 'македония',\n",
       " 'болеть',\n",
       " 'единица']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('город', embeddings_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa31dc3",
   "metadata": {},
   "source": [
    "### Skip gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7770e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "window = 6\n",
    "for sent in sentences[:1000]:\n",
    "    for i in range(len(sent)-1):\n",
    "        word = sent[i] # target\n",
    "        \n",
    "        context = sent[max(0, i-window):i] + sent[i+1:i+window] \n",
    "\n",
    "        for context_word in context:\n",
    "            X.append(word)\n",
    "            y.append(context_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c82f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af3a671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batches_sg(sentences, probs_id, inverse_probability, window = 6, batch_size=1000):\n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "                for context_word in context:\n",
    "                    X_target.append(word)\n",
    "                    X_context.append(context_word)\n",
    "                    y.append(1)\n",
    "                    \n",
    "                    X_target.append(word)\n",
    "                    X_context.append(weighted_choice(list(probs_id.keys()), inverse_probability))\n",
    "                    y.append(0)\n",
    "                    \n",
    "                    if len(X_target) >= batch_size:\n",
    "                        X_target = np.array(X_target)\n",
    "                        X_context = np.array(X_context)\n",
    "                        y = np.array(y)\n",
    "                        yield ((X_target, X_context), y)\n",
    "                        X_target = []\n",
    "                        X_context = []\n",
    "                        y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9e5e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = tf.keras.layers.Input(shape=(1,))\n",
    "inputs_context = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "embeddings_target = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = tf.keras.layers.Flatten()(embeddings_target)\n",
    "context = tf.keras.layers.Flatten()(embeddings_context)\n",
    "\n",
    "dot = tf.keras.layers.Dot(1)([target, context])\n",
    "outputs = tf.keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6a6f324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 4219s 844ms/step - loss: 0.4615 - accuracy: 0.7877 - val_loss: 0.4573 - val_accuracy: 0.7897\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 4107s 822ms/step - loss: 0.4264 - accuracy: 0.8146 - val_loss: 0.4990 - val_accuracy: 0.7674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3313fb9d0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen_batches_sg(sentences[:15000], probs_id=probs_id, inverse_probability=inverse_probability, window=6),\n",
    "          validation_data=gen_batches_sg(sentences[15000:], probs_id=probs_id, inverse_probability=inverse_probability, window=6),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=5000,\n",
    "          validation_steps=30,\n",
    "         epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a2b567f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03482859, -0.02956803, -0.00371065, ..., -0.00815315,\n",
       "        -0.0448302 , -0.04319881],\n",
       "       [ 0.01334755, -0.18266134,  0.2607386 , ..., -0.14163136,\n",
       "        -0.1567577 , -0.18487763],\n",
       "       [ 0.01021713,  0.03332259, -0.04486002, ..., -0.05881575,\n",
       "         0.10570815, -0.03603128],\n",
       "       ...,\n",
       "       [ 0.02594272,  0.00636439,  0.04116179, ..., -0.02128221,\n",
       "        -0.043621  , -0.04552773],\n",
       "       [-0.01464182,  0.06716199, -0.02285857, ..., -0.06867998,\n",
       "         0.00737145, -0.0313918 ],\n",
       "       [-0.05586654,  0.05969387, -0.15152314, ..., -0.07764118,\n",
       "         0.10195328,  0.02472008]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0ae7362e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['окно',\n",
       " 'сохранил',\n",
       " 'бледно',\n",
       " 'советника',\n",
       " 'знает',\n",
       " 'кандидатом',\n",
       " 'костюм',\n",
       " 'устья',\n",
       " 'тираж',\n",
       " 'скалы']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('окно', embeddings_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "388cea81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['кот',\n",
       " '«когда',\n",
       " 'конёк',\n",
       " 'сравнивать',\n",
       " 'косово',\n",
       " 'ракетный',\n",
       " 'взаимодействие',\n",
       " 'огонь',\n",
       " 'символический',\n",
       " 'указывать']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('кот', embeddings_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8480ce64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['город',\n",
       " 'маркса',\n",
       " 'спектакле',\n",
       " 'колледж',\n",
       " 'марки',\n",
       " 'петрика',\n",
       " 'участники',\n",
       " '53',\n",
       " 'певицы',\n",
       " 'красными']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('город', embeddings_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1b353",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25811ea6",
   "metadata": {},
   "source": [
    "Результаты обеих моделей выглядят не очень впечатляюще :( Наверное, это связано с тем, что мы поменяли частотность (искали наименее частотные слова)... Видимо, в таком случае и CBOW, и skip-gram плохо справляются."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37987d52",
   "metadata": {},
   "source": [
    "# Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5adfa5a",
   "metadata": {},
   "source": [
    "Обучите 1 word2vec и 1 fastext модель в gensim. В каждой из модели нужно задать все параметры, которые мы разбирали на семинаре. Заданные значения должны отличаться от дефолтных и от тех, что мы использовали на семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "373dc46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9c849e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = open('wiki_data.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "86c14cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [preprocess(sent) for sent in wiki] # такой же preprocessing как в 1 задании (с лемматизацией)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45cb84",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2dce4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2a2c979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             vector_size=200, \n",
    "                             min_count=15, \n",
    "                             max_vocab_size=10000,\n",
    "                             ns_exponent=0.95,\n",
    "                             sg=0, \n",
    "                             hs=1,\n",
    "                             negative=7,\n",
    "                             sample=1e-4,\n",
    "                             cbow_mean=2,\n",
    "                             window=4,\n",
    "                             epochs=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f2853807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('посёлок', 0.48544546961784363),\n",
       " ('столица', 0.47791996598243713),\n",
       " ('центр', 0.43370017409324646),\n",
       " ('окраина', 0.42700716853141785),\n",
       " ('округ', 0.4022160768508911),\n",
       " ('район', 0.39803963899612427),\n",
       " ('близ', 0.3927867114543915),\n",
       " ('городок', 0.38611865043640137),\n",
       " ('регион', 0.37758299708366394),\n",
       " ('провинция', 0.3706863820552826)]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('город')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc1aa9",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ba92eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = gensim.models.FastText(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a2f139c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = gensim.models.FastText(texts, \n",
    "                            min_n=5, \n",
    "                            max_n=9,\n",
    "                            vector_size=200, \n",
    "                            min_count=15, \n",
    "                            max_vocab_size=10000,\n",
    "                            ns_exponent=0.95,\n",
    "                            sg=0, \n",
    "                            hs=1,\n",
    "                            negative=7,\n",
    "                            sample=1e-4,\n",
    "                            cbow_mean=2,\n",
    "                            window=4,\n",
    "                            epochs=9\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "dbf98ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('столица', 0.6029025912284851),\n",
       " ('городок', 0.5638772249221802),\n",
       " ('посёлок', 0.5025506615638733),\n",
       " ('центр', 0.5010461211204529),\n",
       " ('близ', 0.4815688729286194),\n",
       " ('округ', 0.4643416106700897),\n",
       " ('район', 0.4493108093738556),\n",
       " ('окраина', 0.42306315898895264),\n",
       " ('регион', 0.4223270118236542),\n",
       " ('провинция', 0.4209226369857788)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar('город')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e328d042",
   "metadata": {},
   "source": [
    "# Задание 3 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e94c0f",
   "metadata": {},
   "source": [
    "Используя датасет для классификации (labeled.csv) и простую нейронную сеть (последняя модель в семинаре), оцените качество полученных эмбедингов в задании 1 и 2 (4 набора эмбедингов), также проверьте 1 любую из предобученных моделей с rus-vectores (но только не tayga_upos_skipgram_300_2_2019). Какая модель показывает наилучший результат?\n",
    "\n",
    "Убедитесь, что для каждой модели вы корректно воспроизводите пайплайн предобработки (в 1 задании у вас лемматизация, не забудьте ее применить к датасету для классификации; у выбранной предобученной модели может быть своя специфичная предобработка - ее нужно воспроизвести)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "fa12b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "ef598ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14412, 6)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb87df7",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "30979a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['norm_text'] = data.comment.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0cc6f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_lab = Counter()\n",
    "\n",
    "for text in data['norm_text']:\n",
    "    vocab_lab.update(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "dae5d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab_lab = set()\n",
    "\n",
    "for word in vocab_lab:\n",
    "    if vocab_lab[word] > 5:\n",
    "        filtered_vocab_lab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "355fd24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6309"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_vocab_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a01c0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_lab = { 'PAD':0}\n",
    "\n",
    "for word in filtered_vocab_lab:\n",
    "    word2id_lab[word] = len(word2id_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "2b3bbb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6310"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "ebd9b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_lab = {i:word for word, i in word2id_lab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "73d8bdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6310"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "dc861941",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X = []\n",
    "\n",
    "for tokens in data['norm_text']:\n",
    "    ids = [word2id_lab[token] for token in tokens if token in word2id_lab]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "5bc7548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=150)\n",
    "y = data.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "bf78ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10d94b",
   "metadata": {},
   "source": [
    "## Эмбеддинги из 1 задания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f05e6",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "329cca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_cbow = np.zeros((len(word2id_lab), 300))\n",
    "\n",
    "for word, i in word2id_lab.items():\n",
    "\n",
    "    if word == 'PAD':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        weights_cbow[i] = embeddings_cbow[word2id[word]]\n",
    "    \n",
    "    except KeyError:\n",
    "        continue\n",
    "        weights_cbow[i] = embeddings_cbow[word2id['опрагпллирао']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "677d0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id_lab), output_dim=300, \n",
    "                                       trainable=False,\n",
    "                                       weights=[weights_cbow])(inputs, )\n",
    "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f712a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfd27d",
   "metadata": {},
   "source": [
    "### Skip gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c44ef5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_sg = np.zeros((len(word2id_lab), 300))\n",
    "\n",
    "for word, i in word2id_lab.items():\n",
    "\n",
    "    if word == 'PAD':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        weights_sg[i] = embeddings_sg[word2id[word]]\n",
    "    \n",
    "    except KeyError:\n",
    "        continue\n",
    "        weights_sg[i] = embeddings_sg[word2id['опрагпллирао']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e2905824",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id_lab), output_dim=300, \n",
    "                                       trainable=False,\n",
    "                                       weights=[weights_sg])(inputs, )\n",
    "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf157264",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7999ddb",
   "metadata": {},
   "source": [
    "## Эмбеддинги из 2 задания (gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3878651",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "cf70dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_w2v = np.zeros((len(word2id_lab), 200))\n",
    "\n",
    "for word, i in word2id_lab.items():\n",
    "\n",
    "    if word == 'PAD':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        weights_w2v[i] = w2v.wv[word]\n",
    "    \n",
    "    except KeyError:\n",
    "        continue\n",
    "        weights_w2v[i] = w2v.wv['опрагпллирао']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8f0193f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id_lab), output_dim=200, \n",
    "                                       trainable=False,\n",
    "                                       weights=[weights_w2v])(inputs, )\n",
    "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52450c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5eef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a83b827",
   "metadata": {},
   "source": [
    "### Fastext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "1b084eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ft = np.zeros((len(word2id_lab), 200))\n",
    "\n",
    "for word, i in word2id_lab.items():\n",
    "\n",
    "    if word == 'PAD':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        weights_ft[i] = ft.wv[word]\n",
    "    \n",
    "    except KeyError:\n",
    "        continue\n",
    "        weights_ft[i] = ft.wv['опрагпллирао']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "17bce61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id_lab), output_dim=200, \n",
    "                                       trainable=False,\n",
    "                                       weights=[weights_ft])(inputs, )\n",
    "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4334236",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb717cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41663ab",
   "metadata": {},
   "source": [
    "## Предобученная модель с Rus vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2467813f",
   "metadata": {},
   "source": [
    "Скачаем **ruscorpora_upos_cbow_300_20_2019** с rusvectores (https://rusvectores.org/ru/models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "eaaaab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3ae6f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_mystem(text):  # from https://github.com/akutuzov/webvectors/blob/master/preprocessing/rusvectores_tutorial.ipynb\n",
    "\n",
    "    processed = m.analyze(text)\n",
    "    tagged = []\n",
    "    for w in processed:\n",
    "        if \"analysis\" not in w:\n",
    "            continue\n",
    "        \n",
    "        if not len(w[\"analysis\"]):\n",
    "            lemma = w[\"text\"]\n",
    "            pos = \"UNKN\"\n",
    "        else:\n",
    "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = w[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "        tagged.append(lemma.lower() + '_' + pos)\n",
    "      \n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "21651579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "2912f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tag_mystem'] = data.comment.apply(tag_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9d637b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>preprocessed_mystem</th>\n",
       "      <th>tag_mystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10116</th>\n",
       "      <td>ну так лицензией это никогда и не было. Неудив...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ну, так, лицензия, это, никогда, и, не, быть,...</td>\n",
       "      <td>[ну, так, лицензия, это, никогда, и, не, быть,...</td>\n",
       "      <td>[ну_PART, так_ADVPRO, лицензия_S, это_PART, ни...</td>\n",
       "      <td>[ну_PART, так_ADVPRO, лицензия_S, это_PART, ни...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>Ну тут, имхо, от магазина конкретного зависит ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ну, тут, имхо, от, магазин, конкретный, завис...</td>\n",
       "      <td>[ну, тут, имхо, от, магазин, конкретный, завис...</td>\n",
       "      <td>[ну_PART, тут_ADVPRO, имхо_ADV, от_PR, магазин...</td>\n",
       "      <td>[ну_PART, тут_ADVPRO, имхо_ADV, от_PR, магазин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>Балбес твой дед, олень\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[балбес, твой, дед, олень]</td>\n",
       "      <td>[балбес, твой, дед, олень]</td>\n",
       "      <td>[балбес_S, твой_APRO, дед_S, олень_S]</td>\n",
       "      <td>[балбес_S, твой_APRO, дед_S, олень_S]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>Ну владелец то один. Что мешает передать телеф...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ну, владелец, то, один, что, мешать, передать...</td>\n",
       "      <td>[ну, владелец, то, один, что, мешать, передать...</td>\n",
       "      <td>[ну_PART, владелец_S, то_PART, один_APRO, что_...</td>\n",
       "      <td>[ну_PART, владелец_S, то_PART, один_APRO, что_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>сколько осталось до следующего крушения?\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[сколько, остаться, до, следующий, крушение]</td>\n",
       "      <td>[сколько, остаться, до, следующий, крушение]</td>\n",
       "      <td>[сколько_ADV, оставаться_V, до_PR, следующий_A...</td>\n",
       "      <td>[сколько_ADV, оставаться_V, до_PR, следующий_A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic  \\\n",
       "10116  ну так лицензией это никогда и не было. Неудив...    0.0   \n",
       "1262   Ну тут, имхо, от магазина конкретного зависит ...    0.0   \n",
       "3676                            Балбес твой дед, олень\\n    1.0   \n",
       "7911   Ну владелец то один. Что мешает передать телеф...    0.0   \n",
       "7446          сколько осталось до следующего крушения?\\n    0.0   \n",
       "\n",
       "                                               norm_text  \\\n",
       "10116  [ну, так, лицензия, это, никогда, и, не, быть,...   \n",
       "1262   [ну, тут, имхо, от, магазин, конкретный, завис...   \n",
       "3676                          [балбес, твой, дед, олень]   \n",
       "7911   [ну, владелец, то, один, что, мешать, передать...   \n",
       "7446        [сколько, остаться, до, следующий, крушение]   \n",
       "\n",
       "                                            preprocessed  \\\n",
       "10116  [ну, так, лицензия, это, никогда, и, не, быть,...   \n",
       "1262   [ну, тут, имхо, от, магазин, конкретный, завис...   \n",
       "3676                          [балбес, твой, дед, олень]   \n",
       "7911   [ну, владелец, то, один, что, мешать, передать...   \n",
       "7446        [сколько, остаться, до, следующий, крушение]   \n",
       "\n",
       "                                     preprocessed_mystem  \\\n",
       "10116  [ну_PART, так_ADVPRO, лицензия_S, это_PART, ни...   \n",
       "1262   [ну_PART, тут_ADVPRO, имхо_ADV, от_PR, магазин...   \n",
       "3676               [балбес_S, твой_APRO, дед_S, олень_S]   \n",
       "7911   [ну_PART, владелец_S, то_PART, один_APRO, что_...   \n",
       "7446   [сколько_ADV, оставаться_V, до_PR, следующий_A...   \n",
       "\n",
       "                                              tag_mystem  \n",
       "10116  [ну_PART, так_ADVPRO, лицензия_S, это_PART, ни...  \n",
       "1262   [ну_PART, тут_ADVPRO, имхо_ADV, от_PR, магазин...  \n",
       "3676               [балбес_S, твой_APRO, дед_S, олень_S]  \n",
       "7911   [ну_PART, владелец_S, то_PART, один_APRO, что_...  \n",
       "7446   [сколько_ADV, оставаться_V, до_PR, следующий_A...  "
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f0f3a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_rv = Counter()\n",
    "\n",
    "for text in data.tag_mystem:\n",
    "    vocab_rv.update(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "be67b873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32925"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b86a21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_rv = {'PAD': 0}\n",
    "\n",
    "for word in vocab_rv:\n",
    "    word2id_rv[word] = len(word2id_rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "84f0c037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32926"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id_rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1363a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_rv = {i: word for word, i in word2id_rv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1fec0a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32926"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word_rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e88eabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for tokens in data.tag_mystem:\n",
    "    ids = [word2id_rv[token] for token in tokens if token in word2id_rv]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ab2f0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=100)\n",
    "y = data.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "fcb24822",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "f7da63e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "56159b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_rv = np.zeros((len(word2id_rv), 300))\n",
    "\n",
    "for word, i in word2id_rv.items():\n",
    "\n",
    "    if word == 'PAD':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        weights_rv[i] = model[word]\n",
    "    \n",
    "    except KeyError:\n",
    "        continue\n",
    "        weights_rv[i] = model['опрагпллирао']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "98581201",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id_rv), output_dim=300, \n",
    "                                       trainable=False,\n",
    "                                       weights=[weights_rv])(inputs, )\n",
    "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "48edaf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "406/406 [==============================] - 3s 4ms/step - loss: 0.6330 - accuracy: 0.6651 - val_loss: 0.6117 - val_accuracy: 0.6567\n",
      "Epoch 2/30\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.6031 - accuracy: 0.6661 - val_loss: 0.6068 - val_accuracy: 0.6567\n",
      "Epoch 3/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5987 - accuracy: 0.6662 - val_loss: 0.6056 - val_accuracy: 0.6574\n",
      "Epoch 4/30\n",
      "406/406 [==============================] - 2s 6ms/step - loss: 0.5964 - accuracy: 0.6665 - val_loss: 0.6048 - val_accuracy: 0.6588\n",
      "Epoch 5/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5948 - accuracy: 0.6666 - val_loss: 0.6043 - val_accuracy: 0.6595\n",
      "Epoch 6/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5935 - accuracy: 0.6668 - val_loss: 0.6041 - val_accuracy: 0.6609\n",
      "Epoch 7/30\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.5925 - accuracy: 0.6665 - val_loss: 0.6037 - val_accuracy: 0.6616\n",
      "Epoch 8/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5917 - accuracy: 0.6692 - val_loss: 0.6036 - val_accuracy: 0.6616\n",
      "Epoch 9/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5910 - accuracy: 0.6685 - val_loss: 0.6034 - val_accuracy: 0.6637\n",
      "Epoch 10/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5904 - accuracy: 0.6704 - val_loss: 0.6032 - val_accuracy: 0.6630\n",
      "Epoch 11/30\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.5898 - accuracy: 0.6705 - val_loss: 0.6030 - val_accuracy: 0.6650\n",
      "Epoch 12/30\n",
      "406/406 [==============================] - 2s 6ms/step - loss: 0.5893 - accuracy: 0.6709 - val_loss: 0.6029 - val_accuracy: 0.6650\n",
      "Epoch 13/30\n",
      "406/406 [==============================] - 2s 6ms/step - loss: 0.5889 - accuracy: 0.6710 - val_loss: 0.6027 - val_accuracy: 0.6650\n",
      "Epoch 14/30\n",
      "406/406 [==============================] - 2s 6ms/step - loss: 0.5885 - accuracy: 0.6711 - val_loss: 0.6027 - val_accuracy: 0.6650\n",
      "Epoch 15/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5881 - accuracy: 0.6711 - val_loss: 0.6025 - val_accuracy: 0.6650\n",
      "Epoch 16/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5877 - accuracy: 0.6714 - val_loss: 0.6024 - val_accuracy: 0.6657\n",
      "Epoch 17/30\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.5874 - accuracy: 0.6719 - val_loss: 0.6023 - val_accuracy: 0.6650\n",
      "Epoch 18/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5871 - accuracy: 0.6715 - val_loss: 0.6020 - val_accuracy: 0.6650\n",
      "Epoch 19/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5868 - accuracy: 0.6719 - val_loss: 0.6020 - val_accuracy: 0.6650\n",
      "Epoch 20/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5865 - accuracy: 0.6721 - val_loss: 0.6020 - val_accuracy: 0.6657\n",
      "Epoch 21/30\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.5863 - accuracy: 0.6716 - val_loss: 0.6018 - val_accuracy: 0.6664\n",
      "Epoch 22/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5860 - accuracy: 0.6726 - val_loss: 0.6018 - val_accuracy: 0.6664\n",
      "Epoch 23/30\n",
      "406/406 [==============================] - 2s 5ms/step - loss: 0.5858 - accuracy: 0.6723 - val_loss: 0.6015 - val_accuracy: 0.6657\n",
      "Epoch 24/30\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.5856 - accuracy: 0.6728 - val_loss: 0.6015 - val_accuracy: 0.6657\n",
      "Epoch 25/30\n",
      "406/406 [==============================] - 1s 3ms/step - loss: 0.5853 - accuracy: 0.6734 - val_loss: 0.6013 - val_accuracy: 0.6650\n",
      "Epoch 26/30\n",
      "406/406 [==============================] - 1s 3ms/step - loss: 0.5851 - accuracy: 0.6731 - val_loss: 0.6013 - val_accuracy: 0.6650\n",
      "Epoch 27/30\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.5849 - accuracy: 0.6735 - val_loss: 0.6012 - val_accuracy: 0.6657\n",
      "Epoch 28/30\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.5847 - accuracy: 0.6736 - val_loss: 0.6012 - val_accuracy: 0.6657\n",
      "Epoch 29/30\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.5845 - accuracy: 0.6738 - val_loss: 0.6011 - val_accuracy: 0.6650\n",
      "Epoch 30/30\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.5843 - accuracy: 0.6736 - val_loss: 0.6010 - val_accuracy: 0.6644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff32cd89610>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "23159662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976eae9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
