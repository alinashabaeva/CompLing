{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ca41e2",
   "metadata": {
    "id": "d0ca41e2"
   },
   "source": [
    "# Домашнее задание № 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57da61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_eng = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0588a6",
   "metadata": {
    "id": "6f0588a6"
   },
   "source": [
    "### Задание 1 Реализовать алгоритм Леска и проверить его на реальном датасете (8 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5283f",
   "metadata": {
    "id": "d6a5283f"
   },
   "source": [
    "Ворднет можно использовать для дизамбигуации. Самый простой алгоритм дизамбигуации - алгоритм Леска. В нём нужное значение слова находится через пересечение слов контекста, в котором употреблено это слово, с определениями значений слова из ворднета. Значение с максимальным пересечением - нужное."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f082cd",
   "metadata": {
    "id": "f6f082cd"
   },
   "source": [
    "Реализуйте его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "668e6803",
   "metadata": {
    "id": "668e6803"
   },
   "outputs": [],
   "source": [
    "def lesk(word, sentence):\n",
    "    \n",
    "    bestsense = 0\n",
    "    maxoverlap = 0\n",
    "    \n",
    "    sentence = [lemmatizer.lemmatize(word) for word in sentence if word not in stopwords_eng]\n",
    "    synsets = wn.synsets(word)\n",
    "    \n",
    "    for i, synset in enumerate(synsets):\n",
    "        definition = synset.definition().lower().split()\n",
    "        definition = [lemmatizer.lemmatize(word) for word in definition if word not in stopwords_eng]\n",
    "        overlap = len(list(set(sentence) & set(definition)))\n",
    "        \n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = i\n",
    "       \n",
    "    return bestsense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f815be9",
   "metadata": {
    "id": "2f815be9"
   },
   "source": [
    "Работать функция должна как-то так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bc4d08",
   "metadata": {
    "id": "67bc4d08",
    "outputId": "8a981875-00f6-47c3-8f87-69caaf0a2328"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# на вход подается элемент результата работы уже написанной вами функции get_words_in_context\n",
    "lesk('day', 'some point or period in time'.split()) # для примера контекст совпадает с одним из определений\n",
    "# а на выходе индекс подходящего синсета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14db176f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some point or period in time'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('day')[1].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965d2dce",
   "metadata": {
    "id": "965d2dce",
    "outputId": "a1f5260a-43ac-4cad-ff33-55a7f8686bfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('day.n.01'),\n",
       " Synset('day.n.02'),\n",
       " Synset('day.n.03'),\n",
       " Synset('day.n.04'),\n",
       " Synset('day.n.05'),\n",
       " Synset('day.n.06'),\n",
       " Synset('day.n.07'),\n",
       " Synset('sidereal_day.n.01'),\n",
       " Synset('day.n.09'),\n",
       " Synset('day.n.10')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "204a4cb0",
   "metadata": {
    "id": "204a4cb0",
    "outputId": "18a24845-f59f-4b2f-e3f1-e01b891f5b12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some point or period in time'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# с помощью этого индекса достаем нужный синсет\n",
    "wn.synsets('day')[1].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8997f76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it should arrive any day now',\n",
       " 'after that day she never trusted him again',\n",
       " 'those were the days',\n",
       " 'these days it is not unusual']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('day')[1].examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a4309c",
   "metadata": {
    "id": "d1a4309c"
   },
   "source": [
    "**Проверьте насколько хорошо работает такой метод на датасете из семинара**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf01fee",
   "metadata": {
    "id": "ecf01fee"
   },
   "source": [
    "Корпус состоит из предложений, где у каждого слова три поля - значение, лемма и само слово. Значение пустое, когда слово однозначное, а у многозначных слов стоит тэг вида **'long%3:00:02::'** Это тэг wordnet'ного формата"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11363d",
   "metadata": {
    "id": "9b11363d"
   },
   "source": [
    "Вот так можно достать соответствующий этому тэгу синсет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5fefa16",
   "metadata": {
    "id": "f5fefa16",
    "outputId": "4d0e3fe9-30a9-45b7-b1fe-853be8b35d6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('review.v.01')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma_from_key('review%2:31:00::').synset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb068f3",
   "metadata": {
    "id": "3bb068f3"
   },
   "source": [
    "Когда с помощью алгоритма Леска вы найдете подходящее значение, их можно просто сравнить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f4039c",
   "metadata": {
    "id": "b2bc390d",
    "outputId": "717c3255-1379-4f88-fd57-4c7ede792a53"
   },
   "outputs": [],
   "source": [
    "# wn.synsets('long')[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3cbf2d",
   "metadata": {
    "id": "bd3cbf2d",
    "outputId": "a94e5887-1cd6-48e2-99bb-0258289bab70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тут подходит второй синсет (!в вашем решении вместо индекса единицы будет результат работы функции lesk)\n",
    "wn.synsets('long')[1] == wn.lemma_from_key('long%3:00:02::').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eca9e9e6",
   "metadata": {
    "id": "eca9e9e6",
    "outputId": "03fd0fb9-c706-464e-dfec-afcde5ae7159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Synset('hanker.v.01'), False),\n",
       " (Synset('long.a.01'), True),\n",
       " (Synset('long.a.02'), False),\n",
       " (Synset('long.s.03'), False),\n",
       " (Synset('retentive.a.01'), False),\n",
       " (Synset('long.a.05'), False),\n",
       " (Synset('long.a.06'), False),\n",
       " (Synset('long.s.07'), False),\n",
       " (Synset('farseeing.s.02'), False),\n",
       " (Synset('long.s.09'), False),\n",
       " (Synset('long.r.01'), False),\n",
       " (Synset('long.r.02'), False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# можно сравнить со всеми, чтобы убедиться\n",
    "[(syns, wn.synsets('long')[i] == wn.lemma_from_key('long%3:00:02::').synset()) \n",
    "  for i, syns in enumerate(wn.synsets('long'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b8806",
   "metadata": {
    "id": "799b8806"
   },
   "source": [
    "**Вам нужно для каждого многозначного слова (т.е. у него есть тэг в первом поле) с помощью алгоритма Леска предсказать нужный синсет и сравнить с правильным. Посчитайте процент правильных предсказаний (accuracy).**\n",
    "\n",
    "Если считается слишком долго, возьмите поменьше предложений (например, только тысячу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d263063",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus_wsd_50k.txt') as file:\n",
    "    corpus = file.read().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "676874d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wsd = []\n",
    "for sent in corpus:\n",
    "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "393c524a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'how', 'How'],\n",
       " ['long%3:00:02::', 'long', 'long'],\n",
       " ['', 'have', 'has'],\n",
       " ['', 'it', 'it'],\n",
       " ['be%2:42:03::', 'be', 'been'],\n",
       " ['', 'since', 'since'],\n",
       " ['', 'you', 'you'],\n",
       " ['review%2:31:00::', 'review', 'reviewed'],\n",
       " ['', 'the', 'the'],\n",
       " ['objective%1:09:00::', 'objective', 'objectives'],\n",
       " ['', 'of', 'of'],\n",
       " ['', 'you', 'your'],\n",
       " ['benefit%1:21:00::', 'benefit', 'benefit'],\n",
       " ['', 'and', 'and'],\n",
       " ['service%1:04:07::', 'service', 'service'],\n",
       " ['program%1:09:01::', 'program', 'program'],\n",
       " ['', '?', '?']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_wsd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "016ffc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lesk(n):\n",
    "    accuracy = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for sent in corpus_wsd:\n",
    "        try:\n",
    "            sent_tokens = [word[2].lower() for word in sent]\n",
    "            for i, word in enumerate(sent):\n",
    "                if word[0]:\n",
    "                    total += 1\n",
    "                    context = sent_tokens[max(0, i-5):i] + sent_tokens[i+1:i+5]\n",
    "                    lesk = lesk(word[1], context)\n",
    "                    if wn.synsets(word[1])[lesk] == wn.lemma_from_key(word[0]).synset():\n",
    "                        correct += 1\n",
    "        except IndexError:\n",
    "            pass\n",
    "    accuracy = correct/total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "942e64ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4687490882111432"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lesk(corpus_wsd[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b45d4",
   "metadata": {
    "id": "c48b45d4"
   },
   "source": [
    "### Задание 2* (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ef129",
   "metadata": {
    "id": "c57ef129"
   },
   "source": [
    "В семинаре для WSI на данных Диалога использовался только Fastext. Попробуйте заменить его на адаграм (обучите свою модель или используйте предобученную out.pkl или https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib), а также поэкспериментируйте с разными алгоритмами кластеризации и их параметрами (можно использовать только те алгоритмы, которые обучаются достаточно быстро)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e5ea3",
   "metadata": {
    "id": "b89e5ea3"
   },
   "source": [
    "Для каждого эксперимента рассчитайте ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c17e25c",
   "metadata": {
    "id": "1c17e25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/lopuhin/python-adagram.git\n",
      "  Cloning https://github.com/lopuhin/python-adagram.git to /private/var/folders/78/prt6vf5x0yvd8c8qqcz2vz2m0000gn/T/pip-req-build-vt0ny7eo\n",
      "  Running command git clone -q https://github.com/lopuhin/python-adagram.git /private/var/folders/78/prt6vf5x0yvd8c8qqcz2vz2m0000gn/T/pip-req-build-vt0ny7eo\n",
      "Requirement already satisfied: cython in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from adagram==0.0.1) (0.29.23)\n",
      "Requirement already satisfied: joblib in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from adagram==0.0.1) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.9 in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from adagram==0.0.1) (1.20.1)\n",
      "Requirement already satisfied: six in /Users/AlyaMac/opt/anaconda3/lib/python3.8/site-packages (from adagram==0.0.1) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/lopuhin/python-adagram.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc929ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93b9fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.cluster import AffinityPropagation, AgglomerativeClustering, DBSCAN, \\\n",
    "                            KMeans, MiniBatchKMeans, Birch, MeanShift, SpectralClustering\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca75f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c2b3f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-5, 339-344</td>\n",
       "      <td>замок владимира мономаха в любече . многочисле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-16, 17-22, 188-193</td>\n",
       "      <td>шильонский замок замок шильйон ( ) , известный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299-304</td>\n",
       "      <td>проведения архитектурно - археологических рабо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111-116</td>\n",
       "      <td>топи с . , л . белокуров легенда о завещании м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134-139, 262-267</td>\n",
       "      <td>великий князь литовский гедимин после успешной...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_id   word  gold_sense_id  predict_sense_id              positions  \\\n",
       "0           1  замок              1               NaN           0-5, 339-344   \n",
       "1           2  замок              1               NaN  11-16, 17-22, 188-193   \n",
       "2           3  замок              1               NaN                299-304   \n",
       "3           4  замок              1               NaN                111-116   \n",
       "4           5  замок              1               NaN       134-139, 262-267   \n",
       "\n",
       "                                             context  \n",
       "0  замок владимира мономаха в любече . многочисле...  \n",
       "1  шильонский замок замок шильйон ( ) , известный...  \n",
       "2  проведения архитектурно - археологических рабо...  \n",
       "3  топи с . , л . белокуров легенда о завещании м...  \n",
       "4  великий князь литовский гедимин после успешной...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f4ed608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \n",
    "    words = [token.text.strip(punct) for token in list(razdel_tokenize(text))]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops_2]\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81ea4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vm = adagram.VectorModel.load(\"out.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW7.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
